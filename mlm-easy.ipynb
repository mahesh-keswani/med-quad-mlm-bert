{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Reference: https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c\nfrom transformers import BertTokenizer, BertForMaskedLM\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForMaskedLM.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:54:14.18427Z","iopub.execute_input":"2022-05-31T07:54:14.185106Z","iopub.status.idle":"2022-05-31T07:54:18.668519Z","shell.execute_reply.started":"2022-05-31T07:54:14.185068Z","shell.execute_reply":"2022-05-31T07:54:18.667754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport tensorflow as tf\n\npath = \"../input/medquad-dataset/ProcessedData.csv\"\ndf = pd.read_csv(path)\n\nanswers = df['Answers'].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:22:10.974236Z","iopub.execute_input":"2022-05-31T07:22:10.974881Z","iopub.status.idle":"2022-05-31T07:22:11.364508Z","shell.execute_reply.started":"2022-05-31T07:22:10.974845Z","shell.execute_reply":"2022-05-31T07:22:11.363713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_words = set()\nfor answer in answers:\n    answer = answer.lower()\n    answer = re.sub(\n        \"[%s]\" % re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"), \"\", answer\n    )\n    answer = re.sub(r'(\\t*)+', '', answer)\n    words = answer.split(\" \")\n    unique_words.update(words)\n\nprint(\"Number of unique words\", len(unique_words))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:22:12.91751Z","iopub.execute_input":"2022-05-31T07:22:12.918122Z","iopub.status.idle":"2022-05-31T07:22:29.533395Z","shell.execute_reply.started":"2022-05-31T07:22:12.918056Z","shell.execute_reply":"2022-05-31T07:22:29.532584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets view 10 words\nlist(unique_words)[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:22:36.678306Z","iopub.execute_input":"2022-05-31T07:22:36.67907Z","iopub.status.idle":"2022-05-31T07:22:36.690015Z","shell.execute_reply.started":"2022-05-31T07:22:36.679034Z","shell.execute_reply":"2022-05-31T07:22:36.689309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_added_toks = tokenizer.add_tokens(unique_words)\nprint('We have added', num_added_toks, 'tokens')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:54:35.745798Z","iopub.execute_input":"2022-05-31T07:54:35.746143Z","iopub.status.idle":"2022-05-31T07:54:36.28829Z","shell.execute_reply.started":"2022-05-31T07:54:35.746114Z","shell.execute_reply":"2022-05-31T07:54:36.287446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:54:38.366573Z","iopub.execute_input":"2022-05-31T07:54:38.367223Z","iopub.status.idle":"2022-05-31T07:54:38.729083Z","shell.execute_reply.started":"2022-05-31T07:54:38.367185Z","shell.execute_reply":"2022-05-31T07:54:38.728272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(answers, return_tensors='pt', max_length=512, truncation=True, padding='max_length')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:23:01.197197Z","iopub.execute_input":"2022-05-31T07:23:01.197575Z","iopub.status.idle":"2022-05-31T07:34:51.986749Z","shell.execute_reply.started":"2022-05-31T07:23:01.197543Z","shell.execute_reply":"2022-05-31T07:34:51.98584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:38:30.030238Z","iopub.execute_input":"2022-05-31T07:38:30.03065Z","iopub.status.idle":"2022-05-31T07:38:30.043732Z","shell.execute_reply.started":"2022-05-31T07:38:30.030613Z","shell.execute_reply":"2022-05-31T07:38:30.042433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs['labels'] = inputs.input_ids.detach().clone()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:38:34.17023Z","iopub.execute_input":"2022-05-31T07:38:34.170634Z","iopub.status.idle":"2022-05-31T07:38:34.214219Z","shell.execute_reply.started":"2022-05-31T07:38:34.170602Z","shell.execute_reply":"2022-05-31T07:38:34.213389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs.keys()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:38:36.271907Z","iopub.execute_input":"2022-05-31T07:38:36.27226Z","iopub.status.idle":"2022-05-31T07:38:36.27788Z","shell.execute_reply.started":"2022-05-31T07:38:36.27223Z","shell.execute_reply":"2022-05-31T07:38:36.277162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create random array of floats with equal dimensions to input_ids tensor\nrand = torch.rand(inputs.input_ids.shape)\n\n# create mask array\nmask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n           (inputs.input_ids != 102) * (inputs.input_ids != 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:39:18.178452Z","iopub.execute_input":"2022-05-31T07:39:18.178978Z","iopub.status.idle":"2022-05-31T07:39:18.297977Z","shell.execute_reply.started":"2022-05-31T07:39:18.178942Z","shell.execute_reply":"2022-05-31T07:39:18.29714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_arr","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:39:20.509182Z","iopub.execute_input":"2022-05-31T07:39:20.509553Z","iopub.status.idle":"2022-05-31T07:39:20.516165Z","shell.execute_reply.started":"2022-05-31T07:39:20.509521Z","shell.execute_reply":"2022-05-31T07:39:20.515177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# And now we take take the indices of each True value, within each individual vector.\nselection = []\n\nfor i in range(inputs.input_ids.shape[0]):\n    selection.append(\n        torch.flatten(mask_arr[i].nonzero()).tolist()\n    )","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:39:26.863132Z","iopub.execute_input":"2022-05-31T07:39:26.86397Z","iopub.status.idle":"2022-05-31T07:39:27.087934Z","shell.execute_reply.started":"2022-05-31T07:39:26.863925Z","shell.execute_reply":"2022-05-31T07:39:27.087154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selection[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:39:28.944659Z","iopub.execute_input":"2022-05-31T07:39:28.944994Z","iopub.status.idle":"2022-05-31T07:39:28.951412Z","shell.execute_reply.started":"2022-05-31T07:39:28.944966Z","shell.execute_reply":"2022-05-31T07:39:28.950595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Then apply these indices to each respective row in input_ids, assigning each of the values at these indices as 103 (id for MASK token)\nfor i in range(inputs.input_ids.shape[0]):\n    inputs.input_ids[i, selection[i]] = 103","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:39:33.816016Z","iopub.execute_input":"2022-05-31T07:39:33.81637Z","iopub.status.idle":"2022-05-31T07:39:34.084527Z","shell.execute_reply.started":"2022-05-31T07:39:33.81634Z","shell.execute_reply":"2022-05-31T07:39:34.083713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs.input_ids","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:39:36.103088Z","iopub.execute_input":"2022-05-31T07:39:36.10348Z","iopub.status.idle":"2022-05-31T07:39:36.113167Z","shell.execute_reply.started":"2022-05-31T07:39:36.103448Z","shell.execute_reply":"2022-05-31T07:39:36.111694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    We can see the value 103 assigned in the same position as the True value is found in the \n    mask_arr tensor.\n    The inputs tensors are now ready — and we can begin setting them up to be fed into our model\n    during training.\n    During training, we’ll be using a PyTorch DataLoader to load our data. To use this, we’ll \n    need to format our data into a PyTorch Dataset object.\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-29T16:25:01.853369Z","iopub.execute_input":"2022-05-29T16:25:01.853715Z","iopub.status.idle":"2022-05-29T16:25:01.861046Z","shell.execute_reply.started":"2022-05-29T16:25:01.853686Z","shell.execute_reply":"2022-05-29T16:25:01.859156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MeditationsDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n    def __len__(self):\n        return len(self.encodings.input_ids)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:54:57.920698Z","iopub.execute_input":"2022-05-31T07:54:57.92105Z","iopub.status.idle":"2022-05-31T07:54:57.926676Z","shell.execute_reply.started":"2022-05-31T07:54:57.92102Z","shell.execute_reply":"2022-05-31T07:54:57.925853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = MeditationsDataset(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:55:00.05771Z","iopub.execute_input":"2022-05-31T07:55:00.058342Z","iopub.status.idle":"2022-05-31T07:55:00.062479Z","shell.execute_reply.started":"2022-05-31T07:55:00.058305Z","shell.execute_reply":"2022-05-31T07:55:00.061413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with batch_size = 16, \"CUDA out of memory\" issue was there, so reduced the batch_size, other possible ways to handle\n# https://stackoverflow.com/questions/59129812/how-to-avoid-cuda-out-of-memory-in-pytorch\nloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:55:02.443478Z","iopub.execute_input":"2022-05-31T07:55:02.444069Z","iopub.status.idle":"2022-05-31T07:55:02.4483Z","shell.execute_reply.started":"2022-05-31T07:55:02.444031Z","shell.execute_reply":"2022-05-31T07:55:02.447475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# and move our model over to the selected device\nmodel.to(device)\n# activate training mode\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:55:04.410798Z","iopub.execute_input":"2022-05-31T07:55:04.411578Z","iopub.status.idle":"2022-05-31T07:55:09.518011Z","shell.execute_reply.started":"2022-05-31T07:55:04.411542Z","shell.execute_reply":"2022-05-31T07:55:09.517272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n# initialize optimizer\noptim = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:55:17.465765Z","iopub.execute_input":"2022-05-31T07:55:17.466109Z","iopub.status.idle":"2022-05-31T07:55:17.484544Z","shell.execute_reply.started":"2022-05-31T07:55:17.466079Z","shell.execute_reply":"2022-05-31T07:55:17.483797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we’re finally set up — we can begin training! We format this as a typical training loop in PyTorch.\n\nfrom tqdm import tqdm  # for our progress bar\n\nepochs = 3\n\nfor epoch in range(epochs):\n    # setup loop with TQDM and dataloader\n    loop = tqdm(loader, leave=True)\n    for batch in loop:\n        # initialize calculated gradients (from prev step)\n        optim.zero_grad()\n\n        # pull all tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # process\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        labels=labels)\n        \n        # extract loss\n        loss = outputs.loss\n        \n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        \n        # update parameters\n        optim.step()\n        \n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:55:36.63406Z","iopub.execute_input":"2022-05-31T07:55:36.634412Z","iopub.status.idle":"2022-05-31T08:49:16.763766Z","shell.execute_reply.started":"2022-05-31T07:55:36.634371Z","shell.execute_reply":"2022-05-31T08:49:16.762939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for saving tokenizer\n# BASE_MODEL = \"distilbert-base-multilingual-cased\"\n# tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n# tokenizer.save_pretrained(\"./models/tokenizer/\")\n# tokenizer2 = DistilBertTokenizer.from_pretrained(\"./models/tokenizer/\")\n\n# Also note: tokenizer2 = AutoTokenizer.from_pretrained(\"./models/tokenizer/\"), this does not work\n# instead, DistilBertTokenizer.from_pretrained(\"./models/tokenizer/\"), this works.\ntokenizer.save_pretrained(\"tokenizer_saved\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:50:19.373613Z","iopub.execute_input":"2022-05-31T08:50:19.373954Z","iopub.status.idle":"2022-05-31T08:50:19.405426Z","shell.execute_reply.started":"2022-05-31T08:50:19.373925Z","shell.execute_reply":"2022-05-31T08:50:19.404646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"model_medquad\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:50:22.675783Z","iopub.execute_input":"2022-05-31T08:50:22.67645Z","iopub.status.idle":"2022-05-31T08:50:23.347017Z","shell.execute_reply.started":"2022-05-31T08:50:22.676393Z","shell.execute_reply":"2022-05-31T08:50:23.346218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-29T16:32:36.941121Z","iopub.execute_input":"2022-05-29T16:32:36.941764Z","iopub.status.idle":"2022-05-29T16:32:37.055488Z","shell.execute_reply.started":"2022-05-29T16:32:36.94173Z","shell.execute_reply":"2022-05-29T16:32:37.0541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}